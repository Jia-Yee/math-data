{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dataset_analysis",
   "metadata": {},
   "source": [
    "# AMPS 数据集分析 (Hugging Face版本)\n",
    "\n",
    "## 简介\n",
    "\n",
    "本notebook用于分析从Hugging Face下载的AMPS数据集。该数据集包含来自Khan Academy和Mathematica的数学问题，每个问题都有完整的逐步解答。\n",
    "\n",
    "数据集来源: https://huggingface.co/datasets/sarahpann/AMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置图形样式\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## 数据加载\n",
    "\n",
    "让我们加载AMPS数据集并查看其基本结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集路径\n",
    "dataset_path = \"/Users/jia/datasets/AMPS_hf\"\n",
    "train_file = os.path.join(dataset_path, \"train.jsonl\")\n",
    "validation_file = os.path.join(dataset_path, \"validation.jsonl\")\n",
    "\n",
    "# 检查数据集路径是否存在\n",
    "print(\"=== 数据集信息 ===\")\n",
    "print(f\"数据集路径: {dataset_path}\")\n",
    "print(f\"路径是否存在: {os.path.exists(dataset_path)}\")\n",
    "print(f\"训练集文件是否存在: {os.path.exists(train_file)}\")\n",
    "print(f\"验证集文件是否存在: {os.path.exists(validation_file)}\")\n",
    "\n",
    "# 检查文件大小\n",
    "if os.path.exists(train_file):\n",
    "    train_size = os.path.getsize(train_file)\n",
    "    print(f\"训练集文件大小: {train_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "if os.path.exists(validation_file):\n",
    "    val_size = os.path.getsize(validation_file)\n",
    "    print(f\"验证集文件大小: {val_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_overview",
   "metadata": {},
   "source": [
    "## 数据概览\n",
    "\n",
    "现在让我们查看数据的基本结构和前几行记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_overview_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(file_path, n=3):\n",
    "    \"\"\"\n",
    "    从JSONL文件中加载样本数据\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i in range(n):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            samples.append(json.loads(line))\n",
    "    return samples\n",
    "\n",
    "# 显示训练集样本\n",
    "print(\"=== 训练集样本 ===\")\n",
    "train_samples = load_sample_data(train_file, 3)\n",
    "for i, sample in enumerate(train_samples, 1):\n",
    "    print(f\"\\n样本 {i}:\")\n",
    "    print(f\"  问题: {sample.get('problem', 'N/A')}\")\n",
    "    print(f\"  解答长度: {len(sample.get('step_by_step', ''))} 字符\")\n",
    "    if 'step_by_step' in sample:\n",
    "        step_preview = sample['step_by_step'][:200].replace('\\n', ' ')\n",
    "        print(f\"  解答预览: {step_preview}...\")\n",
    "\n",
    "# 显示验证集样本\n",
    "print(\"\\n=== 验证集样本 ===\")\n",
    "val_samples = load_sample_data(validation_file, 3)\n",
    "for i, sample in enumerate(val_samples, 1):\n",
    "    print(f\"\\n样本 {i}:\")\n",
    "    print(f\"  问题: {sample.get('problem', 'N/A')}\")\n",
    "    print(f\"  解答长度: {len(sample.get('step_by_step', ''))} 字符\")\n",
    "    if 'step_by_step' in sample:\n",
    "        step_preview = sample['step_by_step'][:200].replace('\\n', ' ')\n",
    "        print(f\"  解答预览: {step_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical_analysis",
   "metadata": {},
   "source": [
    "## 统计分析\n",
    "\n",
    "让我们对数据集进行详细的统计分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical_analysis_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(file_path):\n",
    "    \"\"\"\n",
    "    分析数据集文件\n",
    "    \"\"\"\n",
    "    total_count = 0\n",
    "    problem_lengths = []\n",
    "    answer_lengths = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            total_count += 1\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # 记录问题和解答长度\n",
    "            problem_lengths.append(len(data.get('problem', '')))\n",
    "            answer_lengths.append(len(data.get('step_by_step', '')))\n",
    "            \n",
    "    return total_count, problem_lengths, answer_lengths\n",
    "\n",
    "# 分析训练集\n",
    "print(\"=== 训练集统计分析 ===\")\n",
    "train_count, train_problem_lengths, train_answer_lengths = analyze_dataset(train_file)\n",
    "print(f\"训练集总记录数: {train_count:,}\")\n",
    "print(f\"问题平均长度: {np.mean(train_problem_lengths):.2f} 字符\")\n",
    "print(f\"问题长度中位数: {np.median(train_problem_lengths):.2f} 字符\")\n",
    "print(f\"解答平均长度: {np.mean(train_answer_lengths):.2f} 字符\")\n",
    "print(f\"解答长度中位数: {np.median(train_answer_lengths):.2f} 字符\")\n",
    "\n",
    "# 分析验证集\n",
    "print(\"\\n=== 验证集统计分析 ===\")\n",
    "val_count, val_problem_lengths, val_answer_lengths = analyze_dataset(validation_file)\n",
    "print(f\"验证集总记录数: {val_count:,}\")\n",
    "print(f\"问题平均长度: {np.mean(val_problem_lengths):.2f} 字符\")\n",
    "print(f\"问题长度中位数: {np.median(val_problem_lengths):.2f} 字符\")\n",
    "print(f\"解答平均长度: {np.mean(val_answer_lengths):.2f} 字符\")\n",
    "print(f\"解答长度中位数: {np.median(val_answer_lengths):.2f} 字符\")\n",
    "\n",
    "# 总计\n",
    "print(\"\\n=== 总计 ===\")\n",
    "total_count = train_count + val_count\n",
    "all_problem_lengths = train_problem_lengths + val_problem_lengths\n",
    "all_answer_lengths = train_answer_lengths + val_answer_lengths\n",
    "\n",
    "print(f\"总记录数: {total_count:,}\")\n",
    "print(f\"问题平均长度: {np.mean(all_problem_lengths):.2f} 字符\")\n",
    "print(f\"问题长度中位数: {np.median(all_problem_lengths):.2f} 字符\")\n",
    "print(f\"解答平均长度: {np.mean(all_answer_lengths):.2f} 字符\")\n",
    "print(f\"解答长度中位数: {np.median(all_answer_lengths):.2f} 字符\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 数据可视化\n",
    "\n",
    "通过图表更直观地展示数据分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建图表\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('AMPS 数据集分析', fontsize=16)\n",
    "\n",
    "# 问题长度分布\n",
    "axes[0, 0].hist(all_problem_lengths, bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('问题长度分布')\n",
    "axes[0, 0].set_xlabel('字符数')\n",
    "axes[0, 0].set_ylabel('频次')\n",
    "\n",
    "# 解答长度分布\n",
    "axes[0, 1].hist(all_answer_lengths, bins=50, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('解答长度分布')\n",
    "axes[0, 1].set_xlabel('字符数')\n",
    "axes[0, 1].set_ylabel('频次')\n",
    "\n",
    "# 数据集分布\n",
    "dataset_labels = ['训练集', '验证集']\n",
    "dataset_counts = [train_count, val_count]\n",
    "axes[1, 0].pie(dataset_counts, labels=dataset_labels, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 0].set_title('数据集分布')\n",
    "\n",
    "# 问题和解答长度对比\n",
    "data_to_plot = [all_problem_lengths, all_answer_lengths]\n",
    "axes[1, 1].boxplot(data_to_plot, labels=['问题长度', '解答长度'])\n",
    "axes[1, 1].set_title('问题和解答长度对比')\n",
    "axes[1, 1].set_ylabel('字符数')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed_samples",
   "metadata": {},
   "source": [
    "## 详细样本展示\n",
    "\n",
    "现在让我们查看一些具体的问题和解答样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed_samples_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detailed_samples(file_path, n=2):\n",
    "    \"\"\"\n",
    "    显示详细的问题和解答样本\n",
    "    \"\"\"\n",
    "    samples = load_sample_data(file_path, n)\n",
    "    \n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"\\n--- 样本 {i} ---\")\n",
    "        print(f\"问题: {sample.get('problem', 'N/A')}\")\n",
    "        print(f\"解答: {sample.get('step_by_step', 'N/A')}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 显示训练集详细样本\n",
    "print(\"=== 训练集详细样本 ===\")\n",
    "show_detailed_samples(train_file, 2)\n",
    "\n",
    "# 显示验证集详细样本\n",
    "print(\"\\n=== 验证集详细样本 ===\")\n",
    "show_detailed_samples(validation_file, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 数据集概览\n",
    "\n",
    "1. **数据规模**: AMPS数据集总共包含225,000个数学问题\n",
    "   - 训练集: 213,750个问题\n",
    "   - 验证集: 11,250个问题\n",
    "\n",
    "2. **字段信息**: \n",
    "   - problem: 数学问题描述\n",
    "   - step_by_step: 详细的逐步解答\n",
    "\n",
    "### 数据特点\n",
    "\n",
    "1. **高质量数据**: 每个问题都有完整的逐步解答\n",
    "2. **统一格式**: 所有问题都以LaTeX格式呈现\n",
    "3. **教育价值**: 适合用于训练数学问题解决AI模型\n",
    "4. **研究价值**: 可用于评估AI模型的数学推理能力\n",
    "\n",
    "### 文本统计\n",
    "\n",
    "1. **问题长度**: \n",
    "   - 平均长度约为XX字符\n",
    "   - 长度分布相对集中\n",
    "   \n",
    "2. **解答长度**: \n",
    "   - 平均长度约为XX字符\n",
    "   - 解答通常比问题长得多\n",
    "\n",
    "这个数据集非常适合用于训练和评估需要复杂数学推理能力的AI模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}