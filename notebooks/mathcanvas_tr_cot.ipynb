{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of tr_cot Dataset\n",
    "\n",
    "This notebook analyzes the tr_cot dataset stored in parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "DATASET_PATH = \"/Users/jia/datasets/data/tr_cot/train\"\n",
    "\n",
    "# Check if the path exists\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(f\"Dataset path exists: {DATASET_PATH}\")\n",
    "    # List all parquet files\n",
    "    parquet_files = list(Path(DATASET_PATH).glob(\"*.parquet\"))\n",
    "    print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "    for file in parquet_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(f\"Dataset path does not exist: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first parquet file for analysis\n",
    "if 'parquet_files' in locals() and len(parquet_files) > 0:\n",
    "    df = pd.read_parquet(parquet_files[0])\n",
    "    print(f\"Successfully loaded {parquet_files[0].name}\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"No parquet files found\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length statistics if text columns exist\n",
    "text_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        text_columns.append(col)\n",
    "\n",
    "print(f\"Text columns identified: {text_columns}\")\n",
    "\n",
    "for col in text_columns:\n",
    "    if df[col].dtype == 'object' and df[col].notnull().any():\n",
    "        df[f'{col}_length'] = df[col].astype(str).str.len()\n",
    "        print(f\"\\nStatistics for {col} length:\")\n",
    "        print(df[f'{col}_length'].describe())\n",
    "        \n",
    "        # Plot histogram\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(df[f'{col}_length'], bins=50, alpha=0.7)\n",
    "        plt.title(f'Distribution of {col} Length')\n",
    "        plt.xlabel('Length (characters)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image data if present\n",
    "image_columns = [col for col in df.columns if 'image' in col.lower()]\n",
    "print(f\"Potential image columns: {image_columns}\")\n",
    "\n",
    "for col in image_columns:\n",
    "    if col in df.columns:\n",
    "        image_data_exists = df[col].notnull().sum()\n",
    "        total_rows = len(df)\n",
    "        coverage = (image_data_exists / total_rows) * 100\n",
    "        print(f\"\\n{col} column:\")\n",
    "        print(f\"  - Total entries: {total_rows}\")\n",
    "        print(f\"  - Entries with image data: {image_data_exists}\")\n",
    "        print(f\"  - Coverage: {coverage:.2f}%\")\n",
    "        \n",
    "        # Show sample of image data structure\n",
    "        if image_data_exists > 0:\n",
    "            sample = df[col].dropna().iloc[0]\n",
    "            print(f\"  - Sample data type: {type(sample)}\")\n",
    "            if hasattr(sample, '__dict__') or isinstance(sample, (dict, list)):\n",
    "                print(f\"  - Sample data structure: {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "sample_size = min(5, len(df))\n",
    "sample_df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"\\n--- Sample {idx} ---\")\n",
    "    for col in df.columns:\n",
    "        if col not in image_columns:\n",
    "            print(f\"{col}: {row[col]}\")\n",
    "        else:\n",
    "            img_data = row[col]\n",
    "            print(f\"{col}: [Image data - type: {type(img_data).__name__}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to render sample images if possible\n",
    "image_cols = [col for col in df.columns if 'image' in col.lower()]\n",
    "if image_cols and len(df[image_cols].dropna()) > 0:\n",
    "    try:\n",
    "        sample_images = df[image_cols].dropna().head(3)\n",
    "        fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "        if len(sample_images) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (idx, row) in enumerate(sample_images.iterrows()):\n",
    "            img_data = row[image_cols[0]]\n",
    "            # Try to display the image depending on its format\n",
    "            if hasattr(img_data, 'keys') and 'bytes' in img_data.keys():\n",
    "                # Image stored as dict with bytes\n",
    "                import io\n",
    "                from PIL import Image\n",
    "                img_bytes = img_data['bytes']\n",
    "                img = Image.open(io.BytesIO(img_bytes))\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f'Sample {idx}')\n",
    "            elif isinstance(img_data, bytes):\n",
    "                # Direct image bytes\n",
    "                import io\n",
    "                from PIL import Image\n",
    "                img = Image.open(io.BytesIO(img_data))\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f'Sample {idx}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display images: {e}\")\n",
    "else:\n",
    "    print(\"No image columns found or no image data available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}